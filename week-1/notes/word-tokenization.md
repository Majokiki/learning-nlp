# Word Tokenization

NLP task needs to do *text normalization*:

1. Segmenting/tokenizing words in running text
2. Normalizing word formats
3. Segmenting sentences in running text



For example:

> Seussâ€™s **cat** in the hat is different from other **cats**!

- **Lemma**: same stem, part of speech, rough word sense
  - **cat** and **cats** $\implies$ same lemma
- **Wordform**: the full inflected surface form
  - **cat** and **cats** $\implies$ different wordforms



**Type**: an element of the vocabulary

**Token**: an instance of that type in running text